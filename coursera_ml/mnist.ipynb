{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# If you would like to make further imports from Tensorflow, add them here\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run this cell to load the MNIST data\n",
    "\n",
    "mnist_data = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def scale_mnist_data(train_images, test_images):\n",
    "    \"\"\"\n",
    "    This function takes in the training and test images as loaded in the cell above, and scales them\n",
    "    so that they have minimum and maximum values equal to 0 and 1 respectively.\n",
    "    Your function should return a tuple (train_images, test_images) of scaled training and test images.\n",
    "    \"\"\"\n",
    "    return (train_images/255, test_images/255)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run your function on the input data\n",
    "\n",
    "scaled_train_images, scaled_test_images = scale_mnist_data(train_images, test_images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add a dummy channel dimension\n",
    "\n",
    "scaled_train_images = scaled_train_images[..., np.newaxis]\n",
    "scaled_test_images = scaled_test_images[..., np.newaxis]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_model(input_shape):\n",
    "    \"\"\"\n",
    "    This function should build a Sequential model according to the above specification. Ensure the \n",
    "    weights are initialised by providing the input_shape argument in the first layer, given by the\n",
    "    function argument.\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    return Sequential([\n",
    "        Conv2D(8, (3,3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run your function to get the model\n",
    "\n",
    "model = get_model(scaled_train_images[0].shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def compile_model(model):\n",
    "    \"\"\"\n",
    "    This function takes in the model returned from your get_model function, and compiles it with an optimiser,\n",
    "    loss function and metric.\n",
    "    Compile the model using the Adam optimiser (with default settings), the cross-entropy loss function and\n",
    "    accuracy as the only metric. \n",
    "    Your function doesn't need to return anything; the model will be compiled in-place.\n",
    "    \"\"\"\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "    acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics = [acc])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run your function to compile the model\n",
    "\n",
    "compile_model(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_model(model, scaled_train_images, train_labels):\n",
    "    \"\"\"\n",
    "    This function should train the model for 5 epochs on the scaled_train_images and train_labels. \n",
    "    Your function should return the training history, as returned by model.fit.\n",
    "    \"\"\"\n",
    "    return model.fit(scaled_train_images, train_labels, epochs=5, batch_size=256, verbose=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run your function to train the model\n",
    "\n",
    "history = train_model(model, scaled_train_images, train_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run this cell to load the model history into a pandas DataFrame\n",
    "\n",
    "frame = pd.DataFrame(history.history)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run this cell to make the Accuracy vs Epochs plot\n",
    "\n",
    "acc_plot = frame.plot(y=\"sparse_categorical_accuracy\", title=\"Accuracy vs Epochs\", legend=False)\n",
    "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Accuracy\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run this cell to make the Loss vs Epochs plot\n",
    "\n",
    "acc_plot = frame.plot(y=\"loss\", title = \"Loss vs Epochs\",legend=False)\n",
    "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Loss\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def evaluate_model(model, scaled_test_images, test_labels):\n",
    "    \"\"\"\n",
    "    This function should evaluate the model on the scaled_test_images and test_labels. \n",
    "    Your function should return a tuple (test_loss, test_accuracy).\n",
    "    \"\"\"\n",
    "    test_loss, test_accuracy = model.evaluate(scaled_test_images, test_labels)\n",
    "    return (test_loss, test_accuracy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run your function to evaluate the model\n",
    "\n",
    "test_loss, test_accuracy = evaluate_model(model, scaled_test_images, test_labels)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run this cell to get model predictions on randomly selected test images\n",
    "\n",
    "num_test_images = scaled_test_images.shape[0]\n",
    "\n",
    "random_inx = np.random.choice(num_test_images, 4)\n",
    "random_test_images = scaled_test_images[random_inx, ...]\n",
    "random_test_labels = test_labels[random_inx, ...]\n",
    "\n",
    "predictions = model.predict(random_test_images)\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 12))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=-0.2)\n",
    "\n",
    "for i, (prediction, image, label) in enumerate(zip(predictions, random_test_images, random_test_labels)):\n",
    "    axes[i, 0].imshow(np.squeeze(image))\n",
    "    axes[i, 0].get_xaxis().set_visible(False)\n",
    "    axes[i, 0].get_yaxis().set_visible(False)\n",
    "    axes[i, 0].text(10., -1.5, f'Digit {label}')\n",
    "    axes[i, 1].bar(np.arange(len(prediction)), prediction)\n",
    "    axes[i, 1].set_xticks(np.arange(len(prediction)))\n",
    "    axes[i, 1].set_title(f\"Categorical distribution. Model prediction: {np.argmax(prediction)}\")\n",
    "    \n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('.venv': poetry)"
  },
  "interpreter": {
   "hash": "bfb6321a40a2677bd38c78060d467ea21332f4b38ec1567950fe1c796350ed15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}